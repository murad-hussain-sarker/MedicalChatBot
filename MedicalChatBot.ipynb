{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjVqfrZR_DHw",
        "outputId": "c967fb92-e776-4184-be3e-e84a3d9eb80d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ok\n"
          ]
        }
      ],
      "source": [
        "print(\"Ok\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taIShvFl_DH3",
        "outputId": "751fec36-bcb7-4363-d1b0-ddf60efa8279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e:\\\\Bappy\\\\Coding\\\\Youtube\\\\Generative AI\\\\Langchain-Projects\\\\End-to-end-Medical-Chatbot-Generative-AI\\\\research'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O33YELDQ_DH4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pku6Zh9L_DH6",
        "outputId": "26b9e8a8-edde-4858-c2d9-0af338ad0ee1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e:\\\\Bappy\\\\Coding\\\\Youtube\\\\Generative AI\\\\Langchain-Projects\\\\End-to-end-Medical-Chatbot-Generative-AI'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JORpI5jZ_DH7"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLvnmxSu_DH9"
      },
      "outputs": [],
      "source": [
        "#Extract Data From the PDF File\n",
        "def load_pdf_file(data):\n",
        "    loader= DirectoryLoader(data,\n",
        "                            glob=\"*.pdf\",\n",
        "                            loader_cls=PyPDFLoader)\n",
        "\n",
        "    documents=loader.load()\n",
        "\n",
        "    return documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF4L4ucL_DH-"
      },
      "outputs": [],
      "source": [
        "extracted_data=load_pdf_file(data='Data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6uWe2WG_DH_"
      },
      "outputs": [],
      "source": [
        "# extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74xaKqMw_DH_"
      },
      "outputs": [],
      "source": [
        "#Split the Data into Text Chunks\n",
        "def text_split(extracted_data):\n",
        "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "    text_chunks=text_splitter.split_documents(extracted_data)\n",
        "    return text_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ8cbOTQ_DIA",
        "outputId": "c7cd93d4-aa32-4885-fd39-a5b1210f940e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of Text Chunks 7020\n"
          ]
        }
      ],
      "source": [
        "text_chunks=text_split(extracted_data)\n",
        "print(\"Length of Text Chunks\", len(text_chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56ce9YBd_DIB"
      },
      "outputs": [],
      "source": [
        "# text_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeG-Ymcm_DIB",
        "outputId": "0bd76c08-c4ff-4801-ab42-fac6e3cea82d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Anaconda3\\envs\\medibot\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGsXJkHH_DIC"
      },
      "outputs": [],
      "source": [
        "#Download the Embeddings from Hugging Face\n",
        "def download_hugging_face_embeddings():\n",
        "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9m1xsT0_DIC",
        "outputId": "f67d91bd-7f6d-4742-fcde-160ab8a5068e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Bappy Ahmed\\AppData\\Local\\Temp\\ipykernel_21168\\1196424635.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
            "c:\\Anaconda3\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Anaconda3\\envs\\medibot\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embeddings = download_hugging_face_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JclYlJvx_DID",
        "outputId": "e66a4701-aeaa-49a8-e878-788ab64b8494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length 384\n"
          ]
        }
      ],
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "print(\"Length\", len(query_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-TFirsB_DID"
      },
      "outputs": [],
      "source": [
        "# query_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zf-924r_DIE",
        "outputId": "aef18231-f61b-4b19-a824-a7638b6078a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBzkdNws_DIE"
      },
      "outputs": [],
      "source": [
        "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
        "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6wPLLRv_DIF"
      },
      "outputs": [],
      "source": [
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import os\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "index_name = \"medicalbot\"\n",
        "\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=384,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d29_xAy_DIF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6-ZB3wy_DIF"
      },
      "outputs": [],
      "source": [
        "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(\n",
        "    documents=text_chunks,\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_MpXyvV_DIF"
      },
      "outputs": [],
      "source": [
        "# Load Existing index\n",
        "\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
        "docsearch = PineconeVectorStore.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyAi5wxO_DIG",
        "outputId": "d6a66adf-3952-46ba-c572-126ca4601d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1b99c0a6830>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgmWO5T-_DIG"
      },
      "outputs": [],
      "source": [
        "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28qhLUsi_DIG"
      },
      "outputs": [],
      "source": [
        "retrieved_docs = retriever.invoke(\"What is Acne?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UOnolEB_DIH",
        "outputId": "9b4d3336-9194-4d31-84cd-bf1da36b6e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='8cb885ac-f5d7-493b-af21-a4d2457168da', metadata={'page': 37.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='Acidosis seeRespiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when thepores of the skin become clogged with oil, dead skincells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is'),\n",
              " Document(id='34736f1a-f8c1-4f90-908a-fdd3ff2f2568', metadata={'page': 38.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25Acne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceousglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
              " Document(id='8085a4cf-e2bc-48c5-89b5-e334c7525e83', metadata={'page': 239.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='ent purposes. For example, lotions, soaps, gels, andcreams containing benzoyl peroxide or tretinoin may beused to clear up mild to moderately severe acne.Isotretinoin (Accutane) is prescribed only for verysevere, disfiguring acne.\\nAcne is a skin condition that occurs when pores or')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEvMyIh__DIH"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI(temperature=0.4, max_tokens=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJcl3DT__DIH"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrXBa7TS_DII"
      },
      "outputs": [],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVgSYv-E_DII",
        "outputId": "ffaeb0be-773f-450d-e554-7e0d3f95680b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Acromegaly and gigantism are disorders that involve the overproduction of growth hormone, resulting in abnormal growth and enlargement of certain body parts. They can cause a variety of symptoms, including changes in appearance, joint pain, and increased risk of certain health conditions. Treatment options include medication, surgery, and radiation therapy.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOo3Ut8D_DII",
        "outputId": "069dbbbb-0370-4916-eec2-d8dfe07565bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "I don't know.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjnKD2i4_DIJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "medibot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}